## Chainalytic ICON

`Chainalytic ICON` is the successor of link:https://github.com/yudus-lab/chainalytic-framework[Chainalytic Framework] 

It is more efficient and elegant, with better architecture, and well-tailored for ICON blockchain networks.

NOTE: `Chainalytic Framework` is now deprecated and should be used only for reference and study. +
For production, you should go with `Chainalytic ICON`

Jump to <<icon_mainnet_docker>>

Jump to <<icon_local_docker>>

### Intro

`Chainalytic ICON` is the engine for aggregating, transforming, and building new data from blockchain transactions ( also known as *transition functions* ) +

One of core feature is `Chainalytic ICON` runs in form of a "node" ( a bit similar to blockchain node ) and everyone can easily run *Chainalytic ICON node* for any *loopchain-based* network ( ICON mainnet, testnet, tbears, private chains...) and build new data upon their demand. +
Given such ability, it could greatly help ICON developers to interact with their SCORE contract on private *loopchain* network.

*Chainalytic ICON node* contains `Aggregator` and `Provider` service, in which

- Each *data transform* has its own database and kept in sync with one *upstream* blockchain node belong to some network ( e.g. citizen node ) +
- Provides an `aiohttp` JSON-RPC API for other applications to consume data.

Currently, there are 2 built-in data transforms

- `contract_history`
- `stake_history`

We will gradually port transforms from legacy `Chainalytic Framework` in the future. You can also implement your own data transform as your need.

Note that, it is neither analytic framework nor platform, its main purpose is data source backend for other applications, include analytic platforms.

### Provider API Reference

link:API.adoc[Provider API]

## Standalone usage

### Install dependencies ( Ubuntu 20.04 )
[source]
----
sudo apt update
sudo apt install python3-pip libsecp256k1-dev libleveldb-dev pkg-config build-essential
----

### Install `chainalytic-icon` package

[source]
----
python3 -m venv venv
venv/bin/pip install -e .
----

### Init config
[source]
----
./launch -i
----

### Start data aggregation process

_Endpoint info will be loaded from `config.yml` if missing_

[source]
----
./launch -a localhost:5500 -p localhost:5600
----

### Run monitor
[source]
----
./launch -a localhost:5500 -p localhost:5600 m
----

_Console monitoring looks like this_

image::docs/console.png[]

### Stop
[source]
----
./launch -a localhost:5500 -p localhost:5600 stop
----

### Run individual services ( for debugging )

[source]
----
venv/bin/python -m chainalytic_icon.aggregator --endpoint localhost:5500 --working_dir .
venv/bin/python -m chainalytic_icon.provider --endpoint localhost:5600 --working_dir .
----

[[icon_mainnet_docker]]
## Docker setup for ICON Mainnet

_Just clone `sample_docker_deploy` folder in this repo and edit from there_

### Step 1

Go to your cloned `sample_docker_deploy` folder which will contain `Chainalytic-ICON` node database, then edit `docker-compose.yml` like below

[source]
----
version: '3'
services:
  chainalytic-icon:
    image: duyyudus/chainalytic-icon
    container_name: chainalytic-icon
    restart: always
    volumes:
      - /path/to/data/mainnet:/mainnet # Modify this, or skip if not using fast mode `direct_db_access` in `config.yml`
      - ./.chainalytic_icon:/chainalytic_icon/.chainalytic_icon
    ports:
      - 5500:5500
      - 5600:5600
----

### Step 2

Edit `.chainalytic_icon/cfg/config.yml` content, usually just need to edit `network_name`, `loopchain_node_endpoint` and `direct_db_access`

[source]
----
network_name: 'icon_mainnet'

loopchain_node_endpoint: 'https://ctz.solidwallet.io' # Just feel free to choose your favorite node

aggregator_endpoint: '0.0.0.0:5500'
provider_endpoint: '0.0.0.0:5600'

# Only ICON mainnet has this DB backup
chain_db_dir: '/mainnet/.storage/db_CHANGEIP:7100_icon_dex'
score_db_icondex_dir: '/mainnet/.score_data/db/icon_dex'

# 1 for fast reading data from leveldb, 0 for fetching block data from loopchain node via JSON-RPC APIs ( slow )
direct_db_access: 1

transforms:
  - contract_history
  - stake_history

storage_dir: '.chainalytic_icon/{network_name}/db'

transform_storage_dir: '{storage_dir}/{transform_id}_storage'
transform_cache_dir: '{storage_dir}/{transform_id}_cache'

log_dir: '.chainalytic_icon/{network_name}/log'

# 10: DEBUG
# 20: INFO
# 30: WARNING
# 40: ERROR
# 50: CRITICAL
log_level: 30

transform_config:
  contract_history:

    # For efficient storage, 
    # number of txs for each contract should be is limited to latest ones
    # Set to 0 for storing all txs
    max_tx_per_contract: 1000
----

### Step 3

Run Docker compose

`docker-compose up -d`

[[icon_local_docker]]
## Docker setup for ICON local network `tbears` ( used with `ICX Contract Hub` )

Same steps as mainnet, with below `config.yml`

[source]
----
network_name: 'icon_local'

loopchain_node_endpoint: 'http://localhost:9000'

aggregator_endpoint: '0.0.0.0:5500'
provider_endpoint: '0.0.0.0:5600'

# These are irrelevant
chain_db_dir: '/mainnet/.storage/db_CHANGEIP:7100_icon_dex'
score_db_icondex_dir: '/mainnet/.score_data/db/icon_dex'

# Always fetch via JSON-RPC API
direct_db_access: 0

# We need only `contract_history` data transform
transforms:
  - contract_history

storage_dir: '.chainalytic_icon/{network_name}/db'

transform_storage_dir: '{storage_dir}/{transform_id}_storage'
transform_cache_dir: '{storage_dir}/{transform_id}_cache'

log_dir: '.chainalytic_icon/{network_name}/log'

# 10: DEBUG
# 20: INFO
# 30: WARNING
# 40: ERROR
# 50: CRITICAL
log_level: 30

transform_config:
  contract_history:

    # For efficient storage, 
    # number of txs for each contract should be is limited to latest ones
    # Set to 0 for storing all txs
    max_tx_per_contract: 1000
----
